version: '3.8'

services:
  postgres:
    image: postgres:16-alpine
    container_name: nebula-postgres
    environment:
      POSTGRES_DB: idgen
      POSTGRES_USER: idgen
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD:-idgen123}
      PGDATA: /var/lib/postgresql/data/pgdata
    ports:
      - "${POSTGRES_PORT:-5432}:5432"
    volumes:
      - postgres_data:/var/lib/postgresql/data
    deploy:
      resources:
        limits:
          cpus: '2'
          memory: 2G
        reservations:
          cpus: '0.5'
          memory: 512M
    command: >
      -c max_connections=100
      -c shared_buffers=512MB
      -c effective_cache_size=1GB
      -c work_mem=16MB
      -c maintenance_work_mem=128MB
      -c checkpoint_completion_target=0.9
      -c wal_buffers=64MB
      -c default_statistics_target=100
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U idgen -d idgen"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 10s
    restart: unless-stopped
    networks:
      - nebula-network

  redis:
    image: redis:7.2-alpine
    container_name: nebula-redis
    ports:
      - "${REDIS_PORT:-6379}:6379"
    command: >
      redis-server
      --appendonly yes
      --maxmemory 256mb
      --maxmemory-policy allkeys-lru
      --timeout 300
      --tcp-backlog 511
    volumes:
      - redis_data:/data
    deploy:
      resources:
        limits:
          cpus: '0.5'
          memory: 512M
        reservations:
          cpus: '0.1'
          memory: 64M
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 5s
    restart: unless-stopped
    networks:
      - nebula-network

  etcd:
    image: quay.io/coreos/etcd:v3.5.11
    container_name: nebula-etcd
    environment:
      ETCD_NAME: etcd0
      ETCD_SNAPSHOT_COUNT: 10000
    ports:
      - "${ETCD_CLIENT_PORT:-2379}:2379"
      - "${ETCD_PEER_PORT:-2380}:2380"
    volumes:
      - etcd_data:/etcd-data
    command: >
      /usr/local/bin/etcd
      --data-dir=/etcd-data
      --listen-client-urls=http://0.0.0.0:2379
      --advertise-client-urls=http://etcd:2379
      --listen-peer-urls=http://0.0.0.0:2380
      --initial-advertise-peer-urls=http://etcd:2380
      --initial-cluster=etcd0=http://etcd:2380
      --max-request-bytes=1048576
    deploy:
      resources:
        limits:
          cpus: '0.5'
          memory: 512M
        reservations:
          cpus: '0.1'
          memory: 128M
    healthcheck:
      test: ["CMD", "etcdctl", "endpoint", "health"]
      interval: 15s
      timeout: 10s
      retries: 5
      start_period: 10s
    restart: unless-stopped
    networks:
      - nebula-network

  app:
    build:
      context: ..
      dockerfile: docker/Dockerfile
    image: nebula-id:latest
    container_name: nebula-app
    ports:
      - "${APP_HTTP_PORT:-8080}:8080"
      - "${APP_METRICS_PORT:-9091}:9091"
    environment:
      - DATABASE_URL=postgresql://idgen:${POSTGRES_PASSWORD:-idgen123}@postgres:5432/idgen
      - REDIS_URL=redis://redis:6379/0
      - ETCD_ENDPOINTS=etcd:2379
      - DC_ID=${DC_ID:-0}
      - RUST_LOG=${RUST_LOG:-info}
      - RUST_BACKTRACE=0
      - SERVER_HTTP_HOST=0.0.0.0
      - SERVER_HTTP_PORT=8080
      - METRICS_ENABLED=true
      - METRICS_HOST=0.0.0.0
      - METRICS_PORT=9091
    deploy:
      resources:
        limits:
          cpus: '2'
          memory: 2G
        reservations:
          cpus: '0.5'
          memory: 512M
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
      etcd:
        condition: service_healthy
    healthcheck:
      test: ["CMD", "wget", "--spider", "-q", "http://localhost:8080/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 5s
    restart: unless-stopped
    networks:
      - nebula-network
    volumes:
      - cargo_cache:/root/.cargo

volumes:
  postgres_data:
    driver: local
  redis_data:
    driver: local
  etcd_data:
    driver: local
  cargo_cache:
    driver: local

networks:
  nebula-network:
    driver: bridge
    ipam:
      config:
        - subnet: 172.28.0.0/16
