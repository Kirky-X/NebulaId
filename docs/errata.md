# é¡¹ç›®æ–‡æ¡£ä¿®æ­£æ¸…å• (Errata)
## ä¼ä¸šçº§åˆ†å¸ƒå¼ ID ç”Ÿæˆç³»ç»Ÿ

**ç‰ˆæœ¬**: v1.1  
**ä¿®æ­£æ—¥æœŸ**: 2025-12-24  
**ä¿®æ­£è´Ÿè´£äºº**: æŠ€æœ¯å›¢é˜Ÿ  
**çŠ¶æ€**: âœ… å·²å®Œæˆä¿®æ­£

---

## ä¿®æ­£æ¦‚è¿°

æœ¬æ–‡æ¡£é’ˆå¯¹åˆç‰ˆé¡¹ç›®æ–‡æ¡£ï¼ˆPRDã€TDDã€Testã€UATã€Taskï¼‰ä¸­å‘ç°çš„**æŠ€æœ¯å‡†ç¡®æ€§ã€ä¸€è‡´æ€§ã€å®Œæ•´æ€§ã€åˆç†æ€§å’Œå®‰å…¨æ€§**é—®é¢˜è¿›è¡Œç³»ç»Ÿæ€§ä¿®æ­£ã€‚ä¿®æ­£å†…å®¹åŸºäºåŸå§‹æ¶æ„è®¾è®¡æ–‡æ¡£çš„æ·±åº¦åˆ†æã€‚

---

## ä¸€ã€å…³é”®æ€§èƒ½ç›®æ ‡ä¿®æ­£ ğŸ”´ é«˜ä¼˜å…ˆçº§

### é—®é¢˜ 1.1: æ€§èƒ½ç›®æ ‡çŸ›ç›¾

**é—®é¢˜æè¿°**:
- ç°æœ‰æ–‡æ¡£: TDD å®šä¹‰ç›®æ ‡ä¸º **100K QPS**
- åŸå§‹è®¾è®¡: æ¶æ„è®¾è®¡æ–‡æ¡£æ˜ç¡®æå‡º **ç™¾ä¸‡çº§ (1M+ QPS)**
- å½±å“: æ€§èƒ½å·®å¼‚ 10 å€ï¼Œå¯¼è‡´å‹æµ‹æ ‡å‡†ã€èµ„æºé¢„ä¼°ã€æ¶æ„è®¾è®¡å…¨éƒ¨å¤±æ•ˆ

**ä¿®æ­£æ–¹æ¡ˆ**:

#### 1.1.1 PRD ä¿®æ­£

```markdown
### 3.1 æ€§èƒ½éœ€æ±‚

| æŒ‡æ ‡ | ç›®æ ‡å€¼ | éªŒè¯æ–¹æ³• | çŠ¶æ€ |
|------|--------|----------|------|
| **å•å®ä¾‹ QPS** | > 1,000,000 (ç™¾ä¸‡çº§) | å‹åŠ›æµ‹è¯• | â³ å¾…éªŒè¯ |
| **é›†ç¾¤æ€» QPS** | > 10,000,000 (åƒä¸‡çº§) | å‹åŠ›æµ‹è¯• | â³ å¾…éªŒè¯ |
| **P50 å»¶è¿Ÿ** | < 1ms | å‹åŠ›æµ‹è¯• | â³ å¾…éªŒè¯ |
| **P99 å»¶è¿Ÿ** | < 10ms | å‹åŠ›æµ‹è¯• | â³ å¾…éªŒè¯ |
| **P999 å»¶è¿Ÿ** | < 50ms | å‹åŠ›æµ‹è¯• | â³ å¾…éªŒè¯ |
| **å¹¶å‘è¿æ¥æ•°** | > 50,000 | è¿æ¥æ± æµ‹è¯• | â³ å¾…éªŒè¯ |
| **å†…å­˜å ç”¨** | < 4GB | å‹åŠ›æµ‹è¯•ç›‘æ§ | â³ å¾…éªŒè¯ |
```

#### 1.1.2 TDD ä¿®æ­£

```markdown
## ä¸ƒã€æ€§èƒ½ä¼˜åŒ–ç­–ç•¥

### 7.1 ç™¾ä¸‡çº§ QPS ä¼˜åŒ–è·¯å¾„

**ç›®æ ‡**: å•å®ä¾‹ QPS > 1,000,000

**å…³é”®ä¼˜åŒ–ç‚¹**:

1. **é›¶æ‹·è´ IO**
   - ä½¿ç”¨ `Bytes` ä»£æ›¿ `Vec<u8>`
   - ä½¿ç”¨ `tokio::io::copy` é¿å…ç”¨æˆ·æ€æ‹·è´

2. **æ— é”å¹¶å‘**
   - RingBuffer ä½¿ç”¨ CAS æ“ä½œ
   - é¿å…å…¨å±€é”ï¼Œä½¿ç”¨åˆ†ç‰‡é”

3. **å¼‚æ­¥æ‰¹å¤„ç†**
   - æ‰¹é‡ä»æ•°æ®åº“è·å–å·æ®µï¼ˆå•æ¬¡ 10,000+ï¼‰
   - æ‰¹é‡é¢„ç”Ÿæˆ ID (RingBuffer å®¹é‡ 1,000,000)

4. **è¿æ¥æ± ä¼˜åŒ–**
   ```rust
   // PostgreSQL è¿æ¥æ± ï¼ˆç™¾ä¸‡çº§ QPS é…ç½®ï¼‰
   let pool = PgPoolOptions::new()
       .max_connections(200)  // æå‡è‡³ 200
       .min_connections(50)
       .acquire_timeout(Duration::from_secs(3))
       .connect(&database_url)
       .await?;
   ```

5. **çƒ­ç‚¹æ•°æ®ç¼“å­˜**
   - Redis ç¼“å­˜é¢„åˆ†é…çš„å·æ®µï¼ˆTTL 5åˆ†é’Ÿï¼‰
   - æœ¬åœ°å†…å­˜ç¼“å­˜å½“å‰ä½¿ç”¨çš„å·æ®µ
```

#### 1.1.3 Test.md ä¿®æ­£

```markdown
### 4.1 å‹åŠ›æµ‹è¯•

#### æµ‹è¯•ç”¨ä¾‹ T-PERF-001: å•å®ä¾‹ç™¾ä¸‡çº§ QPS å‹æµ‹ â³ å¾…æµ‹è¯•

**å·¥å…·**: wrk + è‡ªå®šä¹‰ Lua è„šæœ¬

**é…ç½®**: 
- å¹¶å‘æ•°: 10,000
- çº¿ç¨‹æ•°: 32
- æŒç»­æ—¶é—´: 10 åˆ†é’Ÿ
- ç›®æ ‡ QPS: 1,000,000+

**éªŒæ”¶æŒ‡æ ‡**:
- [ ] QPS > 1,000,000
- [ ] P50 å»¶è¿Ÿ < 1ms
- [ ] P99 å»¶è¿Ÿ < 10ms
- [ ] P999 å»¶è¿Ÿ < 50ms
- [ ] é”™è¯¯ç‡ < 0.001%
- [ ] CPU ä½¿ç”¨ç‡ < 85%
- [ ] å†…å­˜å ç”¨ < 4GB

**æµ‹è¯•è„šæœ¬**:
```bash
wrk -t 32 -c 10000 -d 600s \
  --latency \
  -s generate.lua \
  http://localhost:8080/api/v1/generate
```

**generate.lua**:
```lua
wrk.method = "POST"
wrk.headers["Content-Type"] = "application/json"
wrk.body = '{"workspace":"test","group":"perf","name":"test-id"}'
```
```

#### 1.1.4 Task.md ä¿®æ­£

```markdown
#### Task 4.1.1: ç™¾ä¸‡çº§ QPS æ€§èƒ½è°ƒä¼˜ ğŸ”´ â³ å¾…å¼€å‘

**æè¿°**: å‹åŠ›æµ‹è¯•å¹¶ä¼˜åŒ–è‡³ç™¾ä¸‡çº§ QPS

**ä¼˜åŒ–è·¯å¾„**:

1. **åŸºå‡†æµ‹è¯•** (ç›®æ ‡: 100K QPS)
   - åŸå§‹å®ç°æ€§èƒ½æµ‹è¯•
   - ç¡®å®šæ€§èƒ½ç“¶é¢ˆï¼ˆCPU/å†…å­˜/IOï¼‰

2. **ç¬¬ä¸€è½®ä¼˜åŒ–** (ç›®æ ‡: 500K QPS)
   - RingBuffer é¢„ç”Ÿæˆä¼˜åŒ–
   - è¿æ¥æ± å‚æ•°è°ƒä¼˜
   - å¼‚æ­¥ä»»åŠ¡è°ƒåº¦ä¼˜åŒ–

3. **ç¬¬äºŒè½®ä¼˜åŒ–** (ç›®æ ‡: 1M QPS)
   - é›¶æ‹·è´ IO
   - æ— é”æ•°æ®ç»“æ„
   - SIMD åŠ é€Ÿï¼ˆå¦‚é€‚ç”¨ï¼‰

4. **ç¬¬ä¸‰è½®ä¼˜åŒ–** (ç›®æ ‡: 1.5M+ QPS)
   - ç«ç„°å›¾åˆ†æçƒ­ç‚¹
   - æ±‡ç¼–çº§ä¼˜åŒ–å…³é”®è·¯å¾„
   - å†…å­˜åˆ†é…å™¨ä¼˜åŒ–ï¼ˆjemallocï¼‰

**é¢„ä¼°å·¥æ—¶**: 5 å¤©

**éªŒæ”¶æ ‡å‡†**:
- [ ] å•å®ä¾‹ QPS > 1,000,000
- [ ] P99 å»¶è¿Ÿ < 10ms
- [ ] CPU ä½¿ç”¨ç‡ < 85%
- [ ] æ€§èƒ½æµ‹è¯•æŠ¥å‘Šå®Œæ•´
```

---

## äºŒã€ç¼“å­˜æ¶æ„ä¿®æ­£ ğŸ”´ é«˜ä¼˜å…ˆçº§

### é—®é¢˜ 2.1: ç¼“å­˜å±‚æœ¯è¯­ä¸é€»è¾‘ä¸ç¬¦

**é—®é¢˜æè¿°**:
- ç°æœ‰æ–‡æ¡£: ä½¿ç”¨ `RingBuffer -> DashMap -> Redis -> DB`
- åŸå§‹è®¾è®¡: `RingBuffer -> DoubleBuffer (åŒç¼“å†²å·æ®µ) -> Redis -> DB`
- é—®é¢˜: DashMap æ˜¯å¹¶å‘å®¹å™¨ï¼Œä¸ç­‰äº"åŒç¼“å†²å·æ®µ"é¢„åŠ è½½é€»è¾‘

**ä¿®æ­£æ–¹æ¡ˆ**:

#### 2.1.1 TDD ç¼“å­˜æ¶æ„é‡æ–°è®¾è®¡

```markdown
### 3.2 ç¼“å­˜å±‚è®¾è®¡ (ä¿®æ­£ç‰ˆ)

#### 3.2.1 ä¸‰çº§ç¼“å­˜æ¶æ„ï¼ˆç§»é™¤ L2 DashMapï¼‰

**è®¾è®¡åŸåˆ™**: ç®€åŒ–ç¼“å­˜å±‚çº§ï¼Œé¿å…è¿‡åº¦è®¾è®¡å¸¦æ¥çš„ä¸€è‡´æ€§é—®é¢˜

```rust
pub struct CacheLayer {
    /// L1: RingBuffer é¢„ç”Ÿæˆæ± ï¼ˆå¿«é€Ÿè·¯å¾„ï¼‰
    ring_buffer: Arc<RingBuffer<Id>>,
    
    /// L2: DoubleBuffer åŒç¼“å†²å·æ®µï¼ˆSegment ç®—æ³•ä¸“ç”¨ï¼‰
    double_buffer: Arc<RwLock<DoubleBuffer>>,
    
    /// L3: Redis å…±äº«ç¼“å­˜ + PostgreSQL æŒä¹…åŒ–
    storage: Arc<Storage>,
}
```

**ç¼“å­˜å±‚çº§è¯´æ˜**:

| å±‚çº§ | ç»„ä»¶ | å®¹é‡ | å‘½ä¸­å»¶è¿Ÿ | ç”¨é€” |
|------|------|------|---------|------|
| **L1** | RingBuffer | 1,000,000 ID | < 100ns | æ— é”å¿«é€Ÿåˆ†é… |
| **L2** | DoubleBuffer | 2ä¸ªå·æ®µ | < 10Î¼s | å·æ®µé¢„åŠ è½½ + æ— ç¼åˆ‡æ¢ |
| **L3** | Redis | ä¸é™ | < 1ms | è·¨èŠ‚ç‚¹å·æ®µå…±äº« |
| **L4** | PostgreSQL | ä¸é™ | < 5ms | å·æ®µæŒä¹…åŒ– |

**ç§»é™¤ DashMap çš„ç†ç”±**:
1. DoubleBuffer å·²ç»æä¾›äº†æœ¬åœ°ç¼“å­˜èƒ½åŠ›
2. é¿å… DashMapã€Redisã€DB ä¸‰å±‚ç¼“å­˜çš„ä¸€è‡´æ€§ç»´æŠ¤
3. ç®€åŒ–ä»£ç é€»è¾‘ï¼Œé™ä½ bug é£é™©

#### 3.2.2 DoubleBuffer åŒç¼“å†²å·æ®µè®¾è®¡

```rust
/// åŒç¼“å†²å·æ®µï¼ˆSegment ç®—æ³•æ ¸å¿ƒï¼‰
pub struct DoubleBuffer {
    /// å½“å‰æ­£åœ¨ä½¿ç”¨çš„å·æ®µ
    current: Arc<AtomicSegment>,
    
    /// é¢„åŠ è½½çš„ä¸‹ä¸€ä¸ªå·æ®µ
    next: Arc<RwLock<Option<Segment>>>,
    
    /// åˆ‡æ¢æ ‡å¿—ä½
    switch_threshold: f64,  // é»˜è®¤ 0.1 (10%)
    
    /// å¼‚æ­¥åŠ è½½ä»»åŠ¡
    loader: Arc<SegmentLoader>,
}

impl DoubleBuffer {
    /// è·å– IDï¼ˆå¿«é€Ÿè·¯å¾„ï¼‰
    pub fn get_id(&self) -> Option<u64> {
        let current = self.current.load();
        let position = current.position.fetch_add(1, Ordering::Relaxed);
        
        // æ£€æŸ¥æ˜¯å¦éœ€è¦åˆ‡æ¢
        if self.should_switch(position, current.end) {
            self.switch_buffer();
        }
        
        if position < current.end {
            Some(position)
        } else {
            None
        }
    }
    
    /// å¼‚æ­¥é¢„åŠ è½½ä¸‹ä¸€ä¸ªå·æ®µ
    async fn preload_next_segment(&self) {
        // è§¦å‘æ¡ä»¶ï¼šå½“å‰å·æ®µå‰©ä½™ < 10%
        // å®ç°ï¼šä» Redis è·å–æˆ–ä» DB åˆ†é…æ–°å·æ®µ
    }
    
    /// æ— ç¼åˆ‡æ¢å·æ®µ
    fn switch_buffer(&self) {
        let mut next_lock = self.next.write().unwrap();
        if let Some(next_segment) = next_lock.take() {
            // åŸå­æ›¿æ¢å½“å‰å·æ®µ
            self.current.store(next_segment);
            
            // ç«‹å³è§¦å‘æ–°çš„é¢„åŠ è½½
            tokio::spawn(async move {
                self.preload_next_segment().await;
            });
        }
    }
}

/// åŸå­å·æ®µï¼ˆæ— é”å¹¶å‘å®‰å…¨ï¼‰
pub struct AtomicSegment {
    start: u64,
    end: u64,
    position: AtomicU64,
    step: u32,
}
```

**å·¥ä½œæµç¨‹**:

```mermaid
sequenceDiagram
    participant App as åº”ç”¨
    participant RB as RingBuffer (L1)
    participant DB as DoubleBuffer (L2)
    participant Redis as Redis (L3)
    participant PG as PostgreSQL (L4)
    
    App->>RB: è¯·æ±‚ ID
    alt RingBuffer æœ‰åº“å­˜
        RB-->>App: è¿”å› ID (< 100ns)
    else RingBuffer ç©º
        RB->>DB: ä» DoubleBuffer è·å–
        DB->>DB: æ£€æŸ¥å½“å‰å·æ®µ
        
        alt å½“å‰å·æ®µå……è¶³ (>10%)
            DB-->>RB: è¿”å› ID
            RB-->>App: è¿”å› ID
        else å½“å‰å·æ®µä¸è¶³ (â‰¤10%)
            par åˆ‡æ¢åˆ°é¢„åŠ è½½å·æ®µ
                DB->>DB: åˆ‡æ¢åˆ° next å·æ®µ
                DB-->>RB: è¿”å› ID
                RB-->>App: è¿”å› ID (æ— é˜»å¡)
            and å¼‚æ­¥åŠ è½½æ–°å·æ®µ
                DB->>Redis: å°è¯•è·å–ç¼“å­˜å·æ®µ
                alt Redis å‘½ä¸­
                    Redis-->>DB: è¿”å›å·æ®µ
                else Redis æœªå‘½ä¸­
                    DB->>PG: åˆ†é…æ–°å·æ®µ (ä¹è§‚é”)
                    PG-->>DB: è¿”å›å·æ®µ [start, end]
                    DB->>Redis: ç¼“å­˜å·æ®µ
                end
                DB->>DB: å¡«å…… next å·æ®µ
            end
        end
    end
```
```

#### 2.1.2 Task.md ä¿®æ­£

```markdown
#### Task 2.1.2: DoubleBuffer åŒç¼“å†²å®ç° ğŸ”´ â³ å¾…å¼€å‘

**æè¿°**: å®ç°å·æ®µåŒç¼“å†²é¢„åŠ è½½æœºåˆ¶ï¼ˆæ›¿ä»£ DashMap æ–¹æ¡ˆï¼‰

**å‰ç½®ä¾èµ–**: Task 1.3.2 (Segment ç®—æ³•)

**å®æ–½æ­¥éª¤**:
1. å®ç° `DoubleBuffer` ç»“æ„ä½“
2. å®ç°åŸå­å·æ®µ `AtomicSegment`
3. å®ç°æ— ç¼åˆ‡æ¢é€»è¾‘ï¼ˆ10% é˜ˆå€¼è§¦å‘ï¼‰
4. å®ç°å¼‚æ­¥é¢„åŠ è½½ï¼ˆtokio::spawnï¼‰
5. å®ç°é¢„åŠ è½½å¤±è´¥é™çº§

**æ ¸å¿ƒä»£ç **:
```rust
pub struct DoubleBuffer {
    current: Arc<AtomicSegment>,
    next: Arc<RwLock<Option<Segment>>>,
    loader: Arc<SegmentLoader>,
}
```

**é¢„ä¼°å·¥æ—¶**: 3 å¤©

**éªŒæ”¶æ ‡å‡†**:
- [ ] å·æ®µåˆ‡æ¢æ— æ„ŸçŸ¥ï¼ˆå»¶è¿Ÿ < 1Î¼sï¼‰
- [ ] é¢„åŠ è½½æˆåŠŸç‡ > 99%
- [ ] å¹¶å‘å®‰å…¨ï¼ˆé€šè¿‡ miri æµ‹è¯•ï¼‰
- [ ] å·æ®µæµªè´¹ç‡ < 5%
- [ ] å•å…ƒæµ‹è¯•è¦†ç›–ç‡ > 85%
```

---

## ä¸‰ã€è·¨æ•°æ®ä¸­å¿ƒæ–¹æ¡ˆè¡¥å…… ğŸ”´ é«˜ä¼˜å…ˆçº§

### é—®é¢˜ 3.1: DC å·æ®µåˆå§‹åŒ–ç¼ºå¤±

**é—®é¢˜æè¿°**:
- åŸå§‹è®¾è®¡: è¯¦ç»†è§„å®šäº†"åˆ†åŒºå·æ®µ + etcd åè°ƒ"æ–¹æ¡ˆ
- ç°æœ‰æ–‡æ¡£: ç¼ºå°‘ DC å·æ®µåˆå§‹åŒ– SQL å’Œ ID åŒºé—´åˆ†é…ç­–ç•¥
- é£é™©: å¤š DC éƒ¨ç½²æ—¶ ID å†²çª

**ä¿®æ­£æ–¹æ¡ˆ**:

#### 3.1.1 TDD è¡¥å……ï¼šDC å·æ®µåˆ†åŒºç­–ç•¥

```markdown
### 2.2 è·¨æ•°æ®ä¸­å¿ƒå·æ®µåˆ†åŒºè®¾è®¡

#### 2.2.1 å·æ®µç©ºé—´åˆ†é…ç­–ç•¥

**è®¾è®¡åŸåˆ™**: ä¸ºæ¯ä¸ªæ•°æ®ä¸­å¿ƒé¢„åˆ†é…ç‹¬ç«‹çš„ ID åŒºé—´ï¼Œé¿å…è·¨ DC ç«äº‰

**åˆ†é…æ–¹æ¡ˆ** (ä»¥ 3 ä¸ª DC ä¸ºä¾‹):

| DC_ID | æ•°æ®ä¸­å¿ƒ | ID èµ·å§‹èŒƒå›´ | ID ç»“æŸèŒƒå›´ | å®¹é‡ |
|-------|---------|------------|------------|------|
| 0 | åŒ—äº¬ | 1,000,000,000,000 | 1,999,999,999,999 | 1ä¸‡äº¿ |
| 1 | ä¸Šæµ· | 2,000,000,000,000 | 2,999,999,999,999 | 1ä¸‡äº¿ |
| 2 | å¹¿å· | 3,000,000,000,000 | 3,999,999,999,999 | 1ä¸‡äº¿ |

**å®¹é‡è®¡ç®—**:
- å• DC å®¹é‡: 1 ä¸‡äº¿ ID
- æŒ‰ 100 ä¸‡ QPS è®¡ç®—ï¼Œå¯ç”¨ 11.5 å¤©
- å®é™…ä¸šåŠ¡åœºæ™¯å¯ç”¨å¤šå¹´ï¼ˆå› ä¸ºå¤šæ•°ä¸šåŠ¡ QPS è¿œä½äºå³°å€¼ï¼‰

#### 2.2.2 åˆå§‹åŒ– SQL

```sql
-- ä¸ºæ¯ä¸ªæ•°æ®ä¸­å¿ƒåˆå§‹åŒ–å·æ®µ
-- å‡è®¾ name_id = 'order-id'

-- DC 0 (åŒ—äº¬)
INSERT INTO segments (name_id, datacenter_id, current_id, max_id, step, base_step)
VALUES (
    'order-id',
    0,  -- DC_ID
    1000000000000,  -- èµ·å§‹ ID
    1999999999999,  -- æœ€å¤§ ID
    10000,  -- åˆå§‹æ­¥é•¿
    10000   -- åŸºå‡†æ­¥é•¿
) ON CONFLICT (name_id, datacenter_id) DO NOTHING;

-- DC 1 (ä¸Šæµ·)
INSERT INTO segments (name_id, datacenter_id, current_id, max_id, step, base_step)
VALUES (
    'order-id',
    1,
    2000000000000,
    2999999999999,
    10000,
    10000
) ON CONFLICT (name_id, datacenter_id) DO NOTHING;

-- DC 2 (å¹¿å·)
INSERT INTO segments (name_id, datacenter_id, current_id, max_id, step, base_step)
VALUES (
    'order-id',
    2,
    3000000000000,
    3999999999999,
    10000,
    10000
) ON CONFLICT (name_id, datacenter_id) DO NOTHING;
```

#### 2.2.3 è‡ªåŠ¨åˆå§‹åŒ–è„šæœ¬

```rust
/// æ•°æ®ä¸­å¿ƒå·æ®µè‡ªåŠ¨åˆå§‹åŒ–
pub async fn initialize_dc_segments(
    pool: &PgPool,
    name_id: &str,
    dc_id: u8,
) -> Result<()> {
    // è®¡ç®—è¯¥ DC çš„ ID åŒºé—´
    let base_range = 1_000_000_000_000u64; // 1 ä¸‡äº¿
    let start_id = (dc_id as u64 + 1) * base_range;
    let max_id = start_id + base_range - 1;
    
    sqlx::query(
        "INSERT INTO segments 
         (name_id, datacenter_id, current_id, max_id, step, base_step)
         VALUES ($1, $2, $3, $4, $5, $6)
         ON CONFLICT (name_id, datacenter_id) DO NOTHING"
    )
    .bind(name_id)
    .bind(dc_id as i16)
    .bind(start_id as i64)
    .bind(max_id as i64)
    .bind(10000)
    .bind(10000)
    .execute(pool)
    .await?;
    
    Ok(())
}
```

#### 2.2.4 DC å·æ®µè€—å°½å‘Šè­¦

```rust
/// ç›‘æ§å·æ®µå‰©ä½™å®¹é‡
pub async fn check_segment_capacity(
    pool: &PgPool,
    name_id: &str,
    dc_id: u8,
) -> Result<f64> {
    let segment: Segment = sqlx::query_as(
        "SELECT * FROM segments 
         WHERE name_id = $1 AND datacenter_id = $2"
    )
    .bind(name_id)
    .bind(dc_id as i16)
    .fetch_one(pool)
    .await?;
    
    let used = segment.current_id - segment.start_id;
    let total = segment.max_id - segment.start_id;
    let usage_ratio = used as f64 / total as f64;
    
    // å‘Šè­¦é˜ˆå€¼ï¼šä½¿ç”¨è¶…è¿‡ 80%
    if usage_ratio > 0.8 {
        warn!(
            "Segment capacity warning: {}% used for {}@DC{}",
            (usage_ratio * 100.0) as u32,
            name_id,
            dc_id
        );
    }
    
    Ok(usage_ratio)
}
```
```

#### 3.1.2 Task.md è¡¥å……

```markdown
#### Task 2.2.4: DC å·æ®µè‡ªåŠ¨åˆå§‹åŒ– ğŸ”´ â³ å¾…å¼€å‘

**æè¿°**: å®ç°æ•°æ®ä¸­å¿ƒå·æ®µè‡ªåŠ¨åˆå§‹åŒ–å’Œå®¹é‡ç›‘æ§

**å‰ç½®ä¾èµ–**: Task 2.2.2 (DC_ID ç®¡ç†)

**å®æ–½æ­¥éª¤**:
1. å®ç°å·æ®µåˆå§‹åŒ–å‡½æ•° `initialize_dc_segments()`
2. åœ¨æœåŠ¡å¯åŠ¨æ—¶è‡ªåŠ¨æ£€æŸ¥å¹¶åˆå§‹åŒ–æœ¬ DC çš„å·æ®µ
3. å®ç°å·æ®µå®¹é‡ç›‘æ§ï¼ˆæ¯å°æ—¶æ£€æŸ¥ä¸€æ¬¡ï¼‰
4. é…ç½®å®¹é‡å‘Šè­¦ï¼ˆä½¿ç”¨ç‡ > 80%ï¼‰

**é¢„ä¼°å·¥æ—¶**: 2 å¤©

**éªŒæ”¶æ ‡å‡†**:
- [ ] æœåŠ¡å¯åŠ¨æ—¶è‡ªåŠ¨åˆå§‹åŒ–å·æ®µ
- [ ] ä¸åŒ DC çš„å·æ®µåŒºé—´ä¸é‡å 
- [ ] å®¹é‡ç›‘æ§æ­£å¸¸å·¥ä½œ
- [ ] å‘Šè­¦è§¦å‘åŠæ—¶ï¼ˆä½¿ç”¨ç‡ > 80%ï¼‰
```

---

## å››ã€æ—¶é’Ÿå›æ‹¨ç­–ç•¥ä¿®æ­£ ğŸŸ  ä¸­ä¼˜å…ˆçº§

### é—®é¢˜ 4.1: æ—¶é’Ÿå›æ‹¨å¤„ç†è¿‡äºç”Ÿç¡¬

**é—®é¢˜æè¿°**:
- ç°æœ‰æ–‡æ¡£: `<5ms` ç­‰å¾…ï¼Œ`>5ms` æŠ¥é”™/é™çº§
- åŸå§‹è®¾è®¡: å¢åŠ "ä¸­ç­‰åå·® (6ms-1000ms) ä½¿ç”¨é€»è¾‘æ—¶é’Ÿ"çš„å¹³æ»‘å¤„ç†
- é£é™©: ç½‘ç»œæŠ–åŠ¨æˆ– NTP åŒæ­¥æ—¶æœåŠ¡å¯ç”¨æ€§æŠ–åŠ¨

**ä¿®æ­£æ–¹æ¡ˆ**:

#### 4.1.1 TDD è¡¥å……ï¼šä¸‰çº§æ—¶é’Ÿå›æ‹¨å¤„ç†

```markdown
### 3.1.4 Snowflake æ—¶é’Ÿå›æ‹¨å¤„ç†ï¼ˆä¿®æ­£ç‰ˆï¼‰

#### ç­–ç•¥åˆ†çº§

| å›æ‹¨ç¨‹åº¦ | æ—¶é—´å·® | å¤„ç†ç­–ç•¥ | å½±å“ |
|---------|--------|---------|------|
| **å¾®å°å›æ‹¨** | < 5ms | è‡ªæ—‹ç­‰å¾… | å»¶è¿Ÿå¢åŠ  < 5ms |
| **ä¸­ç­‰å›æ‹¨** | 6ms - 1000ms | é€»è¾‘æ—¶é’Ÿé€’å¢ | ID æ—¶é—´æˆ³ç•¥æœ‰åå·® |
| **ä¸¥é‡å›æ‹¨** | > 1000ms | ç«‹å³é™çº§è‡³ UUID v7 | åˆ‡æ¢ç®—æ³• |

#### å®ç°ä»£ç 

```rust
pub struct SnowflakeAlgorithm {
    datacenter_id: u8,
    worker_id: u16,
    sequence: AtomicU16,
    last_timestamp: AtomicI64,
    
    /// é€»è¾‘æ—¶é’Ÿï¼ˆç”¨äºå¤„ç†ä¸­ç­‰å›æ‹¨ï¼‰
    logical_clock: AtomicU64,
}

impl SnowflakeAlgorithm {
    pub async fn generate(&self) -> Result<Id> {
        let current_ts = Self::current_millis();
        let last_ts = self.last_timestamp.load(Ordering::Acquire);
        
        // æ—¶é’Ÿå›æ‹¨æ£€æµ‹
        if current_ts < last_ts {
            let drift = last_ts - current_ts;
            
            match drift {
                // å¾®å°å›æ‹¨: è‡ªæ—‹ç­‰å¾…
                0..=5 => {
                    std::hint::spin_loop();
                    tokio::time::sleep(Duration::from_millis(drift as u64)).await;
                    return self.generate().await; // é‡è¯•
                }
                
                // ä¸­ç­‰å›æ‹¨: ä½¿ç”¨é€»è¾‘æ—¶é’Ÿ
                6..=1000 => {
                    warn!("Clock drift detected: {}ms, using logical clock", drift);
                    
                    // é€»è¾‘æ—¶é’Ÿé€’å¢
                    let logical_ts = self.logical_clock.fetch_add(1, Ordering::SeqCst);
                    
                    // ä½¿ç”¨é€»è¾‘æ—¶é’Ÿç”Ÿæˆ ID
                    let id = self.compose_id_with_logical_clock(logical_ts)?;
                    return Ok(id);
                }
                
                // ä¸¥é‡å›æ‹¨: ç«‹å³é™çº§
                _ => {
                    error!("Severe clock backward: {}ms, degrading to UUID v7", drift);
                    return Err(Error::ClockBackward(drift));
                }
            }
        }
        
        // æ­£å¸¸ç”Ÿæˆ
        let sequence = self.get_next_sequence(current_ts)?;
        let id = self.compose_id(current_ts, sequence)?;
        
        // æ›´æ–°é€»è¾‘æ—¶é’Ÿï¼ˆä¿æŒåŒæ­¥ï¼‰
        self.logical_clock.store(current_ts as u64, Ordering::Release);
        
        Ok(id)
    }
    
    /// ä½¿ç”¨é€»è¾‘æ—¶é’Ÿç”Ÿæˆ ID
    fn compose_id_with_logical_clock(&self, logical_ts: u64) -> Result<Id> {
        let sequence = self.get_next_sequence(logical_ts as i64)?;
        
        let id = (logical_ts << 21)
            | ((self.datacenter_id as u64) << 18)
            | ((self.worker_id as u64) << 10)
            | (sequence as u64);
        
        Ok(Id::Numeric(id))
    }
}
```

**å·¥ä½œæµç¨‹**:

```mermaid
flowchart TD
    A[ç”Ÿæˆ ID è¯·æ±‚] --> B{æ£€æµ‹æ—¶é’Ÿ}
    B -->|æ­£å¸¸| C[ä½¿ç”¨ç³»ç»Ÿæ—¶é—´æˆ³]
    B -->|å›æ‹¨ < 5ms| D[è‡ªæ—‹ç­‰å¾…]
    B -->|å›æ‹¨ 6-1000ms| E[ä½¿ç”¨é€»è¾‘æ—¶é’Ÿ]
    B -->|å›æ‹¨ > 1000ms| F[é™çº§è‡³ UUID v7]
    
    C --> G[ç”Ÿæˆ ID]
    D --> B
    E --> H[é€»è¾‘æ—¶é’Ÿ +1]
    H --> G
    F --> I[è§¦å‘å‘Šè­¦]
    I --> J[è¿”å› UUID v7 ID]
    
    G --> K[æ›´æ–°é€»è¾‘æ—¶é’Ÿ]
    K --> L[è¿”å› ID]
```
```

#### 4.1.2 Test.md è¡¥å……

```markdown
#### æµ‹è¯•æ¨¡å—: æ—¶é’Ÿå›æ‹¨å¤„ç† â³ å¾…æµ‹è¯•

**æµ‹è¯•ç”¨ä¾‹ T-SNOW-004: å¾®å°æ—¶é’Ÿå›æ‹¨**
- **æè¿°**: æ¨¡æ‹Ÿ 3ms æ—¶é’Ÿå›æ‹¨
- **æµ‹è¯•æ­¥éª¤**:
  1. ç”Ÿæˆ IDï¼Œè®°å½•æ—¶é—´æˆ³ T1
  2. ä¿®æ”¹ç³»ç»Ÿæ—¶é’Ÿ -3ms
  3. å†æ¬¡ç”Ÿæˆ ID
- **é¢„æœŸç»“æœ**: 
  - [ ] ç­‰å¾… 3ms åæˆåŠŸç”Ÿæˆ
  - [ ] ID ä½¿ç”¨çœŸå®æ—¶é—´æˆ³

**æµ‹è¯•ç”¨ä¾‹ T-SNOW-005: ä¸­ç­‰æ—¶é’Ÿå›æ‹¨**
- **æè¿°**: æ¨¡æ‹Ÿ 100ms æ—¶é’Ÿå›æ‹¨
- **æµ‹è¯•æ­¥éª¤**:
  1. ç”Ÿæˆ IDï¼Œè®°å½•æ—¶é—´æˆ³ T1
  2. ä¿®æ”¹ç³»ç»Ÿæ—¶é’Ÿ -100ms
  3. å†æ¬¡ç”Ÿæˆ ID
- **é¢„æœŸç»“æœ**: 
  - [ ] ç«‹å³æˆåŠŸç”Ÿæˆï¼ˆæ— ç­‰å¾…ï¼‰
  - [ ] ID ä½¿ç”¨é€»è¾‘æ—¶é’Ÿï¼ˆlogical_clock + 1ï¼‰
  - [ ] å‘Šè­¦è¢«è®°å½•

**æµ‹è¯•ç”¨ä¾‹ T-SNOW-006: ä¸¥é‡æ—¶é’Ÿå›æ‹¨**
- **æè¿°**: æ¨¡æ‹Ÿ 2000ms æ—¶é’Ÿå›æ‹¨
- **æµ‹è¯•æ­¥éª¤**:
  1. ç”Ÿæˆ IDï¼Œè®°å½•æ—¶é—´æˆ³ T1
  2. ä¿®æ”¹ç³»ç»Ÿæ—¶é’Ÿ -2000ms
  3. å†æ¬¡ç”Ÿæˆ ID
- **é¢„æœŸç»“æœ**: 
  - [ ] è¿”å›é”™è¯¯æˆ–é™çº§è‡³ UUID v7
  - [ ] å‘Šè­¦è¢«è§¦å‘
  - [ ] æœåŠ¡ä¸ä¸­æ–­
```

#### 4.1.3 Task.md è¡¥å……

```markdown
#### Task 1.3.3: Snowflake ç®—æ³•å®ç°ï¼ˆä¿®æ­£ç‰ˆï¼‰ ğŸ”´ â³ å¾…å¼€å‘

**æè¿°**: å®ç°æ”¹è¿›ç‰ˆé›ªèŠ±ç®—æ³•ï¼ˆå«é€»è¾‘æ—¶é’Ÿï¼‰

**å‰ç½®ä¾èµ–**: Task 1.3.1

**å®æ–½æ­¥éª¤**:
1. å®šä¹‰ ID ç»“æ„ï¼ˆ64ä½ï¼‰
2. å®ç°æ—¶é—´æˆ³ç”Ÿæˆï¼ˆæ¯«ç§’çº§ï¼‰
3. å®ç°åºåˆ—å·ç®¡ç†ï¼ˆå•æ¯«ç§’å†…è‡ªå¢ï¼‰
4. **å®ç°ä¸‰çº§æ—¶é’Ÿå›æ‹¨å¤„ç†** â¬…ï¸ æ–°å¢
   - å¾®å°å›æ‹¨ï¼ˆ< 5msï¼‰: è‡ªæ—‹ç­‰å¾…
   - ä¸­ç­‰å›æ‹¨ï¼ˆ6-1000msï¼‰: é€»è¾‘æ—¶é’Ÿ
   - ä¸¥é‡å›æ‹¨ï¼ˆ> 1000msï¼‰: é™çº§
5. å®ç°é€»è¾‘æ—¶é’Ÿç»´æŠ¤
6. å®ç° ID ç»„è£…å’Œè§£æ

**é¢„ä¼°å·¥æ—¶**: 3 å¤©ï¼ˆåŸ 2 å¤© + 1 å¤©é€»è¾‘æ—¶é’Ÿï¼‰

**éªŒæ”¶æ ‡å‡†**:
- [ ] ID æ ¼å¼æ­£ç¡®ï¼ˆ64ä½ï¼‰
- [ ] ä¸‰çº§æ—¶é’Ÿå›æ‹¨å¤„ç†æ­£ç¡®
- [ ] é€»è¾‘æ—¶é’Ÿå•è°ƒé€’å¢
- [ ] å•æ¯«ç§’æ”¯æŒ 1024 ä¸ª ID
- [ ] å¹¶å‘å®‰å…¨
- [ ] å•å…ƒæµ‹è¯•è¦†ç›–ç‡ > 85%
```

---

## äº”ã€æŠ€æœ¯å‡†ç¡®æ€§ä¿®æ­£ ğŸ”´ é«˜ä¼˜å…ˆçº§

### é—®é¢˜ 5.1: RingBuffer ç±»å‹ä¸å…¼å®¹

**é—®é¢˜æè¿°**:
- ç°æœ‰ä»£ç : `RingBuffer<T>` ä½¿ç”¨ `Vec<AtomicU64>` å­˜å‚¨ ID
- é—®é¢˜: `AtomicU64` æ— æ³•å­˜å‚¨ UUID v7ï¼ˆ128ä½ï¼‰
- é£é™©: è¿è¡Œæ—¶ç±»å‹é”™è¯¯

**ä¿®æ­£æ–¹æ¡ˆ**:

#### 5.1.1 TDD ä¿®æ­£ï¼šRingBuffer é€šç”¨è®¾è®¡

```markdown
### 3.2.3 RingBuffer è®¾è®¡ï¼ˆä¿®æ­£ç‰ˆï¼‰

#### é—®é¢˜åˆ†æ

- **åŸè®¾è®¡**: `Vec<AtomicU64>` åªèƒ½å­˜å‚¨ 64 ä½æ•´æ•°
- **å®é™…éœ€æ±‚**: éœ€è¦å­˜å‚¨ `Id` æšä¸¾ï¼ˆåŒ…å« UUIDï¼Œ128ä½ï¼‰

#### è§£å†³æ–¹æ¡ˆ 1: ä½¿ç”¨ crossbeam çš„ ArrayQueue

```rust
use crossbeam::queue::ArrayQueue;

pub struct RingBuffer {
    /// ä½¿ç”¨ crossbeam çš„æ— é”é˜Ÿåˆ—
    queue: Arc<ArrayQueue<Id>>,
    
    /// å®¹é‡
    capacity: usize,
    
    /// å¡«å……é˜ˆå€¼
    fill_threshold: usize,
    
    /// ç»Ÿè®¡ä¿¡æ¯
    stats: Arc<AtomicStats>,
}

impl RingBuffer {
    pub fn new(capacity: usize) -> Self {
        Self {
            queue: Arc::new(ArrayQueue::new(capacity)),
            capacity,
            fill_threshold: capacity / 10, // 10%
            stats: Arc::new(AtomicStats::default()),
        }
    }
    
    /// è·å– IDï¼ˆO(1) æ—¶é—´å¤æ‚åº¦ï¼‰
    pub fn pop(&self) -> Option<Id> {
        let id = self.queue.pop();
        
        // æ£€æŸ¥æ˜¯å¦éœ€è¦å¼‚æ­¥å¡«å……
        if self.queue.len() < self.fill_threshold {
            self.trigger_async_fill();
        }
        
        id
    }
    
    /// æ‰¹é‡å¡«å……ï¼ˆç”±åå°ä»»åŠ¡è°ƒç”¨ï¼‰
    pub fn push_batch(&self, ids: Vec<Id>) -> Result<usize> {
        let mut pushed = 0;
        for id in ids {
            if self.queue.push(id).is_ok() {
                pushed += 1;
            } else {
                break; // é˜Ÿåˆ—å·²æ»¡
            }
        }
        Ok(pushed)
    }
}
```

#### è§£å†³æ–¹æ¡ˆ 2: ä½¿ç”¨ Box æŒ‡é’ˆï¼ˆå¦‚æœæ€§èƒ½å¯æ¥å—ï¼‰

```rust
pub struct RingBuffer {
    /// ä½¿ç”¨ Box æŒ‡é’ˆé¿å…å¤§å¯¹è±¡æ ˆåˆ†é…
    buffer: Vec<AtomicPtr<Id>>,
    write_pos: AtomicUsize,
    read_pos: AtomicUsize,
    capacity: usize,
}

impl RingBuffer {
    pub fn pop(&self) -> Option<Id> {
        let read = self.read_pos.fetch_add(1, Ordering::Relaxed);
        let write = self.write_pos.load(Ordering::Acquire);
        
        if read < write {
            let ptr = self.buffer[read % self.capacity].load(Ordering::Acquire);
            if !ptr.is_null() {
                // å®‰å…¨ï¼šæˆ‘ä»¬ä¿è¯åªæœ‰ä¸€ä¸ªçº¿ç¨‹ä¼šè¯»è¿™ä¸ªä½ç½®
                unsafe {
                    let id = Box::from_raw(ptr);
                    Some(*id)
                }
            } else {
                None
            }
        } else {
            None
        }
    }
}
```

#### æ¨èæ–¹æ¡ˆ: crossbeam::ArrayQueue

**ç†ç”±**:
1. æˆç†Ÿçš„æ— é”å®ç°ï¼Œç»è¿‡å……åˆ†æµ‹è¯•
2. æ”¯æŒä»»æ„ç±»å‹ `T`
3. æ€§èƒ½ä¼˜ç§€ï¼ˆpop/push < 50nsï¼‰
4. é¿å…æ‰‹åŠ¨å†…å­˜ç®¡ç†

**å†…å­˜å ç”¨è®¡ç®—**:

```rust
// UUID v7: 16 bytes
// æ•°å­— ID: 8 bytes
// å¹³å‡: 12 bytes (å‡è®¾ 70% æ•°å­— ID, 30% UUID)

// RingBuffer å®¹é‡: 1,000,000
// å†…å­˜å ç”¨: 1,000,000 * 12 bytes = 12 MB
```

**æ€§èƒ½å¯¹æ¯”**:

| å®ç°æ–¹å¼ | Pop å»¶è¿Ÿ | Push å»¶è¿Ÿ | å†…å­˜å ç”¨ | å¤æ‚åº¦ |
|---------|---------|---------|---------|--------|
| crossbeam::ArrayQueue | < 50ns | < 50ns | 12 MB | ä½ |
| AtomicPtr + Box | < 100ns | < 100ns | 24 MB | é«˜ |
| è‡ªå®šä¹‰æ— é”é˜Ÿåˆ— | < 30ns | < 30ns | 12 MB | æé«˜ |

**æ¨è**: crossbeam::ArrayQueueï¼ˆå¹³è¡¡æ€§èƒ½å’Œå¤æ‚åº¦ï¼‰
```

#### 5.1.2 Task.md ä¿®æ­£

```markdown
#### Task 2.1.1: RingBuffer å®ç°ï¼ˆä¿®æ­£ç‰ˆï¼‰ ğŸ”´ â³ å¾…å¼€å‘

**æè¿°**: å®ç°æ”¯æŒé€šç”¨ `Id` ç±»å‹çš„é«˜æ€§èƒ½ç¯å½¢ç¼“å†²åŒº

**å‰ç½®ä¾èµ–**: Task 1.3.2

**æŠ€æœ¯é€‰å‹**: crossbeam::queue::ArrayQueue

**å®æ–½æ­¥éª¤**:
1. æ·»åŠ ä¾èµ–: `crossbeam = "0.8"`
2. å®ç° `RingBuffer` ç»“æ„ä½“
   ```rust
   pub struct RingBuffer {
       queue: Arc<ArrayQueue<Id>>,
       capacity: usize,
       fill_threshold: usize,
   }
   ```
3. å®ç° `pop()` æ–¹æ³•ï¼ˆæ— é”ï¼‰
4. å®ç° `push_batch()` æ–¹æ³•
5. å®ç°å¼‚æ­¥å¡«å……è§¦å‘é€»è¾‘
6. å®ç°ç»Ÿè®¡æŒ‡æ ‡ï¼ˆå‘½ä¸­ç‡ã€å¡«å……é¢‘ç‡ï¼‰

**é¢„ä¼°å·¥æ—¶**: 2 å¤©ï¼ˆåŸ 3 å¤©ï¼Œä½¿ç”¨æˆç†Ÿåº“å‡å°‘å¼€å‘é‡ï¼‰

**éªŒæ”¶æ ‡å‡†**:
- [ ] æ”¯æŒ `Id::Numeric` å’Œ `Id::Uuid` ç±»å‹
- [ ] Pop å»¶è¿Ÿ < 100ns
- [ ] å¹¶å‘å®‰å…¨ï¼ˆé€šè¿‡ loom æµ‹è¯•ï¼‰
- [ ] å†…å­˜å ç”¨ < 20 MB (1M å®¹é‡)
- [ ] å•å…ƒæµ‹è¯•è¦†ç›–ç‡ > 90%
```

---

### é—®é¢˜ 5.2: Snowflake ç®—æ³•é˜»å¡é—®é¢˜

**é—®é¢˜æè¿°**:
- ç°æœ‰ä»£ç : æ—¶é’Ÿå›æ‹¨æ—¶ä½¿ç”¨ `tokio::time::sleep`
- é—®é¢˜: é«˜å¹¶å‘åœºæ™¯ä¸‹é˜»å¡ runtime workerï¼Œå¯¼è‡´ååé‡éª¤é™
- é£é™©: æ€§èƒ½æ€¥å‰§ä¸‹é™

**ä¿®æ­£æ–¹æ¡ˆ**:

#### 5.2.1 TDD è¡¥å……ï¼šéé˜»å¡ç­‰å¾…ç­–ç•¥

```markdown
### 3.1.5 Snowflake éé˜»å¡æ—¶é’Ÿå¤„ç†

#### é—®é¢˜

```rust
// âŒ é”™è¯¯ç¤ºä¾‹ï¼šé˜»å¡ async runtime
if timestamp < last_timestamp {
    tokio::time::sleep(Duration::from_millis(5)).await; // é˜»å¡ worker
}
```

#### è§£å†³æ–¹æ¡ˆï¼šè¯·æ±‚é˜Ÿåˆ— + å¼‚æ­¥é€šçŸ¥

```rust
use tokio::sync::mpsc;

pub struct SnowflakeAlgorithm {
    datacenter_id: u8,
    worker_id: u16,
    sequence: AtomicU16,
    last_timestamp: AtomicI64,
    
    /// ç­‰å¾…é˜Ÿåˆ—ï¼ˆç”¨äºæ—¶é’Ÿå›æ‹¨æ—¶çš„è¯·æ±‚ï¼‰
    wait_queue: Arc<Mutex<VecDeque<oneshot::Sender<Id>>>>,
    
    /// åå°æ—¶é’Ÿè¿½èµ¶ä»»åŠ¡
    clock_catcher: Option<JoinHandle<()>>,
}

impl SnowflakeAlgorithm {
    pub async fn generate(&self) -> Result<Id> {
        let current_ts = Self::current_millis();
        let last_ts = self.last_timestamp.load(Ordering::Acquire);
        
        // æ—¶é’Ÿå›æ‹¨æ£€æµ‹
        if current_ts < last_ts {
            let drift = last_ts - current_ts;
            
            if drift <= 5 {
                // å¾®å°å›æ‹¨ï¼šåŠ å…¥ç­‰å¾…é˜Ÿåˆ—ï¼Œç”±åå°ä»»åŠ¡å¤„ç†
                let (tx, rx) = oneshot::channel();
                self.wait_queue.lock().unwrap().push_back(tx);
                
                // éé˜»å¡ç­‰å¾…
                return rx.await.map_err(|_| Error::WaitQueueClosed);
            } else {
                // ä¸­ç­‰/ä¸¥é‡å›æ‹¨ï¼šç«‹å³é™çº§
                return self.handle_clock_drift(drift);
            }
        }
        
        // æ­£å¸¸ç”Ÿæˆ
        self.generate_normal(current_ts)
    }
    
    /// åå°æ—¶é’Ÿè¿½èµ¶ä»»åŠ¡
    async fn clock_catcher_task(self: Arc<Self>) {
        loop {
            tokio::time::sleep(Duration::from_millis(1)).await;
            
            let current_ts = Self::current_millis();
            let last_ts = self.last_timestamp.load(Ordering::Acquire);
            
            // æ—¶é’Ÿå·²è¿½ä¸Šï¼Œå¤„ç†ç­‰å¾…é˜Ÿåˆ—
            if current_ts >= last_ts {
                let mut queue = self.wait_queue.lock().unwrap();
                while let Some(tx) = queue.pop_front() {
                    if let Ok(id) = self.generate_normal(current_ts) {
                        let _ = tx.send(id);
                    }
                }
            }
        }
    }
}
```

**ä¼˜åŠ¿**:
- ä¸é˜»å¡ async runtime worker
- ç­‰å¾…æ—¶å…¶ä»–è¯·æ±‚ä»å¯å¤„ç†
- ååé‡ä¸å—å½±å“
```

---

## å…­ã€æ–‡æ¡£ä¸€è‡´æ€§ä¿®æ­£ ğŸŸ  ä¸­ä¼˜å…ˆçº§

### é—®é¢˜ 6.1: é™çº§é€»è¾‘æµ‹è¯•ç¼ºå¤±

**ä¿®æ­£æ–¹æ¡ˆ**:

#### 6.1.1 Test.md è¡¥å……

```markdown
### 2.4 é™çº§ç­–ç•¥æµ‹è¯•

#### æµ‹è¯•æ¨¡å—: ç®—æ³•é™çº§é“¾ â³ å¾…æµ‹è¯•

**æµ‹è¯•ç”¨ä¾‹ T-DEG-005: å®Œæ•´é™çº§é“¾æµ‹è¯•**
- **æè¿°**: éªŒè¯ Segment â†’ Snowflake â†’ UUID v7 â†’ UUID v4 é™çº§é“¾
- **æµ‹è¯•æ­¥éª¤**:
  1. æ­£å¸¸æƒ…å†µï¼šä½¿ç”¨ Segment
  2. åœæ­¢ PostgreSQLï¼šåˆ‡æ¢è‡³ Snowflake
  3. æ¨¡æ‹Ÿæ—¶é’Ÿå›æ‹¨ï¼šåˆ‡æ¢è‡³ UUID v7
  4. æ¨¡æ‹Ÿ UUID v7 å¤±è´¥ï¼šåˆ‡æ¢è‡³ UUID v4
- **é¢„æœŸç»“æœ**: 
  - [ ] æ¯æ¬¡é™çº§æ—  ID ç”Ÿæˆä¸­æ–­
  - [ ] é™çº§äº‹ä»¶è¢«è®°å½•
  - [ ] å‘Šè­¦è¢«è§¦å‘
  - [ ] é™çº§å“åº”æ—¶é—´ < 1ç§’

**æµ‹è¯•ç”¨ä¾‹ T-DEG-006: è‡ªåŠ¨æ¢å¤æµ‹è¯•**
- **æè¿°**: éªŒè¯æ•…éšœæ¢å¤åè‡ªåŠ¨åˆ‡å›ä¼˜å…ˆç®—æ³•
- **æµ‹è¯•æ­¥éª¤**:
  1. è§¦å‘ PostgreSQL æ•…éšœï¼Œé™çº§è‡³ Snowflake
  2. æŒç»­ç”Ÿæˆ ID 1åˆ†é’Ÿ
  3. æ¢å¤ PostgreSQL
  4. ç­‰å¾…å¥åº·æ£€æŸ¥ï¼ˆ30ç§’ï¼‰
  5. è§‚å¯Ÿç®—æ³•åˆ‡æ¢
- **é¢„æœŸç»“æœ**: 
  - [ ] è‡ªåŠ¨åˆ‡å› Segment ç®—æ³•
  - [ ] åˆ‡æ¢è¿‡ç¨‹æ—  ID é‡å¤
  - [ ] æ¢å¤äº‹ä»¶è¢«è®°å½•
```

---

### é—®é¢˜ 6.2: æœ¯è¯­ä¸ä¸€è‡´

**ä¿®æ­£æ–¹æ¡ˆ**:

#### 6.2.1 ç»Ÿä¸€æœ¯è¯­å®šä¹‰

| åŸæœ¯è¯­ | ç»Ÿä¸€å | ä½¿ç”¨åœºæ™¯ |
|--------|--------|---------|
| ä¸šåŠ¡å•å…ƒ / Business Unit / name | **biz_tag** | ä»£ç ã€APIã€æ•°æ®åº“ |
| æ•°æ®ä¸­å¿ƒ / Data Center / DC | **datacenter** | ä»£ç ã€é…ç½® |
| å·¥ä½œç©ºé—´ / Workspace | **workspace** | æ‰€æœ‰æ–‡æ¡£ |
| åˆ†ç»„ / Group | **group** | æ‰€æœ‰æ–‡æ¡£ |

#### 6.2.2 PRD/TDD/Task å…¨å±€æ›¿æ¢

```markdown
# æ‰€æœ‰æ–‡æ¡£ä¸­æ›¿æ¢
- "ä¸šåŠ¡å•å…ƒ" â†’ "ä¸šåŠ¡æ ‡ç­¾ (biz_tag)"
- API å‚æ•°ä» `name` æ”¹ä¸º `biz_tag`
- æ•°æ®åº“è¡¨ä» `names` æ”¹ä¸º `biz_tags`
```

---

## ä¸ƒã€åˆç†æ€§ä¿®æ­£ ğŸŸ¡ ä½ä¼˜å…ˆçº§

### é—®é¢˜ 7.1: è¿‡åº¦è®¾è®¡ - ç§»é™¤å››çº§ç¼“å­˜

**ä¿®æ­£æ–¹æ¡ˆ**: å·²åœ¨"é—®é¢˜ 2.1"ä¸­ä¿®æ­£ï¼Œç§»é™¤ L2 DashMap

---

### é—®é¢˜ 7.2: worker_id è‡ªåŠ¨åˆ†é…ç¼ºå¤±

**ä¿®æ­£æ–¹æ¡ˆ**:

#### 7.2.1 TDD è¡¥å……

```markdown
### 2.3 Worker ID è‡ªåŠ¨åˆ†é…ï¼ˆåŸºäº etcdï¼‰

#### è®¾è®¡ç›®æ ‡
åœ¨ Kubernetes ç¯å¢ƒä¸‹ï¼ŒPod åŠ¨æ€åˆ›å»ºå’Œé”€æ¯ï¼Œéœ€è¦è‡ªåŠ¨åˆ†é…å’Œå›æ”¶ worker_id

#### å®ç°æ–¹æ¡ˆ

```rust
use etcd_client::{Client, LockOptions};

pub struct WorkerIdAllocator {
    etcd_client: Client,
    datacenter_id: u8,
    worker_id: AtomicU16,
    lease_id: AtomicI64,
}

impl WorkerIdAllocator {
    /// è‡ªåŠ¨åˆ†é… worker_id
    pub async fn allocate(&self) -> Result<u16> {
        let lease = self.etcd_client
            .lease_grant(30, None) // 30 ç§’ç§Ÿçº¦
            .await?;
        
        // å°è¯•æ³¨å†Œ worker_id (0-255)
        for worker_id in 0..256 {
            let key = format!(
                "/idgen/workers/{}/{}",
                self.datacenter_id,
                worker_id
            );
            
            // å°è¯•åˆ›å»ºä¸´æ—¶é”®ï¼ˆå¦‚æœä¸å­˜åœ¨ï¼‰
            let txn = self.etcd_client
                .txn()
                .when([
                    Compare::create_revision(key.clone(), CompareOp::Equal, 0)
                ])
                .and_then([
                    TxnOp::put(key.clone(), "allocated", Some(lease.id()))
                ])
                .or_else([])
                .execute()
                .await?;
            
            if txn.succeeded() {
                // åˆ†é…æˆåŠŸ
                self.worker_id.store(worker_id, Ordering::Release);
                self.lease_id.store(lease.id(), Ordering::Release);
                
                // å¯åŠ¨ç§Ÿçº¦ç»­æœŸä»»åŠ¡
                self.start_keep_alive(lease.id());
                
                return Ok(worker_id);
            }
        }
        
        Err(Error::NoAvailableWorkerId)
    }
    
    /// ç§Ÿçº¦ç»­æœŸï¼ˆåå°ä»»åŠ¡ï¼‰
    fn start_keep_alive(&self, lease_id: i64) {
        let etcd_client = self.etcd_client.clone();
        tokio::spawn(async move {
            loop {
                tokio::time::sleep(Duration::from_secs(10)).await;
                if let Err(e) = etcd_client.lease_keep_alive(lease_id).await {
                    error!("Failed to keep alive lease: {}", e);
                    break;
                }
            }
        });
    }
    
    /// é‡Šæ”¾ worker_idï¼ˆæœåŠ¡å…³é—­æ—¶è°ƒç”¨ï¼‰
    pub async fn release(&self) -> Result<()> {
        let worker_id = self.worker_id.load(Ordering::Acquire);
        let key = format!(
            "/idgen/workers/{}/{}",
            self.datacenter_id,
            worker_id
        );
        
        self.etcd_client.delete(key, None).await?;
        Ok(())
    }
}
```

**å·¥ä½œæµç¨‹**:

```mermaid
sequenceDiagram
    participant Pod as IDæœåŠ¡ Pod
    participant etcd as etcd é›†ç¾¤
    
    Pod->>etcd: åˆ›å»ºç§Ÿçº¦ (TTL 30s)
    etcd-->>Pod: è¿”å› lease_id
    
    loop å°è¯•åˆ†é… worker_id (0-255)
        Pod->>etcd: å°è¯•åˆ›å»º /idgen/workers/{dc}/{id}
        alt é”®ä¸å­˜åœ¨
            etcd-->>Pod: åˆ›å»ºæˆåŠŸ
            Pod->>Pod: è®°å½• worker_id
            Pod->>etcd: å¯åŠ¨ç§Ÿçº¦ç»­æœŸ (æ¯ 10s)
        else é”®å·²å­˜åœ¨
            etcd-->>Pod: åˆ›å»ºå¤±è´¥
            Pod->>Pod: å°è¯•ä¸‹ä¸€ä¸ª ID
        end
    end
    
    loop æœåŠ¡è¿è¡ŒæœŸé—´
        Pod->>etcd: Keep Alive (æ¯ 10s)
        etcd-->>Pod: ç»­æœŸæˆåŠŸ
    end
    
    Pod->>etcd: åˆ é™¤é”®ï¼ˆé‡Šæ”¾ worker_idï¼‰
    etcd-->>Pod: åˆ é™¤æˆåŠŸ
```
```

#### 7.2.2 Task.md è¡¥å……

```markdown
#### Task 2.2.5: Worker ID è‡ªåŠ¨åˆ†é… ğŸŸ  â³ å¾…å¼€å‘

**æè¿°**: å®ç°åŸºäº etcd çš„ worker_id è‡ªåŠ¨åˆ†é…å’Œå›æ”¶

**å‰ç½®ä¾èµ–**: Task 2.2.1 (etcd é›†æˆ)

**å®æ–½æ­¥éª¤**:
1. å®ç° `WorkerIdAllocator` ç»“æ„ä½“
2. å®ç° worker_id åˆ†é…é€»è¾‘ï¼ˆå°è¯• 0-255ï¼‰
3. å®ç°ç§Ÿçº¦ç»­æœŸï¼ˆåå°ä»»åŠ¡ï¼‰
4. å®ç°ä¼˜é›…é‡Šæ”¾ï¼ˆæœåŠ¡å…³é—­æ—¶ï¼‰
5. å®ç°åˆ†é…å¤±è´¥å‘Šè­¦

**é¢„ä¼°å·¥æ—¶**: 2 å¤©

**éªŒæ”¶æ ‡å‡†**:
- [ ] æœåŠ¡å¯åŠ¨æ—¶è‡ªåŠ¨åˆ†é… worker_id
- [ ] ç§Ÿçº¦ç»­æœŸæ­£å¸¸ï¼ˆæ¯ 10ç§’ï¼‰
- [ ] Pod é‡å¯åå¯é‡æ–°åˆ†é…
- [ ] åˆ†é…å¤±è´¥æœ‰æ˜ç¡®å‘Šè­¦
- [ ] å•å…ƒæµ‹è¯•è¦†ç›–ç‡ > 80%
```

---

## å…«ã€å®Œæ•´æ€§è¡¥å…… ğŸŸ  ä¸­ä¼˜å…ˆçº§

### é—®é¢˜ 8.1: ç¯å¢ƒåˆå§‹åŒ–ä»»åŠ¡ç¼ºå¤±

**ä¿®æ­£æ–¹æ¡ˆ**:

#### 8.1.1 Task.md è¡¥å……

```markdown
#### Task 1.0.1: å¼€å‘ç¯å¢ƒå®¹å™¨åŒ–ç¼–æ’ ğŸ”´ â³ å¾…å¼€å‘

**æè¿°**: åˆ›å»º docker-compose ä¸€é”®å¯åŠ¨å¼€å‘ç¯å¢ƒ

**å‰ç½®ä¾èµ–**: æ— 

**å®æ–½æ­¥éª¤**:
1. ç¼–å†™ `docker-compose.yml`
2. é…ç½® PostgreSQL å®¹å™¨ï¼ˆå«åˆå§‹åŒ–è„šæœ¬ï¼‰
3. é…ç½® Redis é›†ç¾¤ï¼ˆ3ä¸»3ä»ï¼‰
4. é…ç½® etcd é›†ç¾¤ï¼ˆ3èŠ‚ç‚¹ï¼‰
5. é…ç½® Prometheus + Grafana
6. ç¼–å†™ `Makefile` å¿«æ·å‘½ä»¤

**docker-compose.yml ç¤ºä¾‹**:
```yaml
version: '3.8'

services:
  postgres:
    image: postgres:16-alpine
    environment:
      POSTGRES_DB: idgen
      POSTGRES_USER: idgen
      POSTGRES_PASSWORD: idgen123
    ports:
      - "5432:5432"
    volumes:
      - ./scripts/init.sql:/docker-entrypoint-initdb.d/init.sql
      - postgres_data:/var/lib/postgresql/data
  
  redis:
    image: redis:7.2-alpine
    ports:
      - "6379:6379"
    command: redis-server --appendonly yes
    volumes:
      - redis_data:/data
  
  etcd:
    image: quay.io/coreos/etcd:v3.5.11
    environment:
      ETCD_NAME: etcd0
      ETCD_LISTEN_CLIENT_URLS: http://0.0.0.0:2379
      ETCD_ADVERTISE_CLIENT_URLS: http://etcd:2379
    ports:
      - "2379:2379"
    volumes:
      - etcd_data:/etcd-data
  
  prometheus:
    image: prom/prometheus:latest
    ports:
      - "9090:9090"
    volumes:
      - ./prometheus.yml:/etc/prometheus/prometheus.yml
  
  grafana:
    image: grafana/grafana:latest
    ports:
      - "3000:3000"
    environment:
      GF_SECURITY_ADMIN_PASSWORD: admin
    volumes:
      - grafana_data:/var/lib/grafana

volumes:
  postgres_data:
  redis_data:
  etcd_data:
  grafana_data:
```

**Makefile ç¤ºä¾‹**:
```makefile
.PHONY: dev-up dev-down dev-logs test

dev-up:
	docker-compose up -d

dev-down:
	docker-compose down

dev-logs:
	docker-compose logs -f

test:
	cargo test --all
```

**é¢„ä¼°å·¥æ—¶**: 1 å¤©

**éªŒæ”¶æ ‡å‡†**:
- [ ] `make dev-up` å¯ä¸€é”®å¯åŠ¨æ‰€æœ‰ä¾èµ–
- [ ] PostgreSQL è‡ªåŠ¨åˆå§‹åŒ–è¡¨ç»“æ„
- [ ] æ‰€æœ‰æœåŠ¡å¥åº·æ£€æŸ¥é€šè¿‡
- [ ] æ–‡æ¡£ä¸­æœ‰è¯¦ç»†çš„ä½¿ç”¨è¯´æ˜
```

---

### é—®é¢˜ 8.2: é”™è¯¯ç å®šä¹‰ç¼ºå¤±

**ä¿®æ­£æ–¹æ¡ˆ**:

#### 8.2.1 TDD è¡¥å……

```markdown
## å…«ã€é”™è¯¯ç è§„èŒƒ

### 8.1 é”™è¯¯ç è®¾è®¡

**æ ¼å¼**: `IDGEN-{æ¨¡å—}-{é”™è¯¯ç }`

**ç¤ºä¾‹**: `IDGEN-SEG-1001`

### 8.2 é”™è¯¯ç è¡¨

| é”™è¯¯ç  | é”™è¯¯åç§° | æè¿° | HTTP çŠ¶æ€ç  |
|-------|---------|------|------------|
| **IDGEN-COMMON-0001** | InvalidRequest | è¯·æ±‚å‚æ•°æ— æ•ˆ | 400 |
| **IDGEN-COMMON-0002** | Unauthorized | æœªæˆæƒè®¿é—® | 401 |
| **IDGEN-COMMON-0003** | RateLimitExceeded | è¶…è¿‡é™æµé˜ˆå€¼ | 429 |
| **IDGEN-COMMON-0004** | InternalError | å†…éƒ¨æœåŠ¡å™¨é”™è¯¯ | 500 |
| **IDGEN-COMMON-0005** | ServiceUnavailable | æœåŠ¡ä¸å¯ç”¨ | 503 |
| **IDGEN-SEG-1001** | SegmentExhausted | å·æ®µè€—å°½ | 500 |
| **IDGEN-SEG-1002** | SegmentAllocateFailed | å·æ®µåˆ†é…å¤±è´¥ | 500 |
| **IDGEN-SEG-1003** | DatabaseUnavailable | æ•°æ®åº“ä¸å¯ç”¨ | 503 |
| **IDGEN-SNOW-2001** | ClockBackward | æ—¶é’Ÿå›æ‹¨ | 500 |
| **IDGEN-SNOW-2002** | SequenceOverflow | åºåˆ—å·æº¢å‡º | 500 |
| **IDGEN-SNOW-2003** | NoAvailableWorkerId | æ— å¯ç”¨ worker_id | 503 |
| **IDGEN-UUID-3001** | UuidGenerateFailed | UUID ç”Ÿæˆå¤±è´¥ | 500 |
| **IDGEN-CACHE-4001** | CacheUnavailable | ç¼“å­˜æœåŠ¡ä¸å¯ç”¨ | 503 |
| **IDGEN-CACHE-4002** | CacheEvicted | ç¼“å­˜è¢«æ·˜æ±° | 500 |

### 8.3 é”™è¯¯å“åº”æ ¼å¼

```json
{
  "error": {
    "code": "IDGEN-SEG-1001",
    "message": "Segment exhausted for biz_tag: order-id",
    "details": {
      "biz_tag": "order-id",
      "datacenter_id": 0,
      "current_id": 1999999999999,
      "max_id": 1999999999999
    },
    "timestamp": "2025-12-23T10:30:00Z",
    "request_id": "req-1234567890"
  }
}
```

### 8.4 å®ç°ä»£ç 

```rust
use serde::{Deserialize, Serialize};

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct ApiError {
    pub code: String,
    pub message: String,
    pub details: serde_json::Value,
    pub timestamp: String,
    pub request_id: String,
}

impl ApiError {
    pub fn segment_exhausted(biz_tag: &str, segment: &Segment) -> Self {
        Self {
            code: "IDGEN-SEG-1001".to_string(),
            message: format!("Segment exhausted for biz_tag: {}", biz_tag),
            details: json!({
                "biz_tag": biz_tag,
                "datacenter_id": segment.datacenter_id,
                "current_id": segment.current_id,
                "max_id": segment.max_id,
            }),
            timestamp: Utc::now().to_rfc3339(),
            request_id: generate_request_id(),
        }
    }
}
```
```

---

## ä¹ã€å®‰å…¨æ€§åŠ å›º ğŸ”´ é«˜ä¼˜å…ˆçº§

### é—®é¢˜ 9.1: API è®¤è¯ç¼ºå¤±

**ä¿®æ­£æ–¹æ¡ˆ**:

#### 9.1.1 TDD è¡¥å……

```markdown
## å…­ã€å®‰å…¨æ€§è®¾è®¡ï¼ˆä¿®æ­£ç‰ˆï¼‰

### 6.1 API Key è®¤è¯

#### è®¾è®¡æ–¹æ¡ˆ

**è®¤è¯æµç¨‹**:
1. ä¸ºæ¯ä¸ª workspace ç”Ÿæˆå”¯ä¸€çš„ API Key
2. è¯·æ±‚å¿…é¡»æºå¸¦ `X-API-Key` è¯·æ±‚å¤´
3. æœåŠ¡ç«¯éªŒè¯ API Key åˆæ³•æ€§
4. è®°å½•æ‰€æœ‰ API è°ƒç”¨åˆ°å®¡è®¡æ—¥å¿—

#### API Key æ ¼å¼

```
æ ¼å¼: idgen_{workspace_id}_{random_32_chars}
ç¤ºä¾‹: idgen_company-a_a1b2c3d4e5f6g7h8i9j0k1l2m3n4o5p6
```

#### æ•°æ®åº“è¡¨ç»“æ„

```sql
CREATE TABLE api_keys (
    id BIGSERIAL PRIMARY KEY,
    workspace_id VARCHAR(64) REFERENCES workspaces(id),
    key_hash VARCHAR(64) NOT NULL,  -- SHA256(api_key)
    key_prefix VARCHAR(16) NOT NULL,  -- ç”¨äºå¿«é€ŸæŸ¥æ‰¾
    description TEXT,
    enabled BOOLEAN DEFAULT TRUE,
    created_at TIMESTAMPTZ DEFAULT NOW(),
    last_used_at TIMESTAMPTZ,
    expires_at TIMESTAMPTZ,
    UNIQUE(key_hash)
);

CREATE INDEX idx_api_keys_prefix ON api_keys(key_prefix);
CREATE INDEX idx_api_keys_workspace ON api_keys(workspace_id);
```

#### å®ç°ä»£ç 

```rust
use axum::http::HeaderMap;
use sha2::{Sha256, Digest};

#[derive(Clone)]
pub struct ApiKeyAuth {
    db_pool: PgPool,
    cache: Arc<DashMap<String, WorkspaceId>>,
}

impl ApiKeyAuth {
    /// éªŒè¯ API Key
    pub async fn verify(&self, headers: &HeaderMap) -> Result<WorkspaceId> {
        // æå– API Key
        let api_key = headers
            .get("X-API-Key")
            .and_then(|v| v.to_str().ok())
            .ok_or(Error::MissingApiKey)?;
        
        // æ£€æŸ¥æœ¬åœ°ç¼“å­˜
        if let Some(workspace_id) = self.cache.get(api_key) {
            return Ok(workspace_id.clone());
        }
        
        // è®¡ç®—å“ˆå¸Œ
        let key_hash = self.hash_api_key(api_key);
        
        // æŸ¥è¯¢æ•°æ®åº“
        let api_key_record: ApiKeyRecord = sqlx::query_as(
            "SELECT * FROM api_keys 
             WHERE key_hash = $1 AND enabled = TRUE 
             AND (expires_at IS NULL OR expires_at > NOW())"
        )
        .bind(&key_hash)
        .fetch_one(&self.db_pool)
        .await
        .map_err(|_| Error::InvalidApiKey)?;
        
        // æ›´æ–°æœ€åä½¿ç”¨æ—¶é—´
        sqlx::query("UPDATE api_keys SET last_used_at = NOW() WHERE id = $1")
            .bind(api_key_record.id)
            .execute(&self.db_pool)
            .await?;
        
        // ç¼“å­˜ç»“æœï¼ˆ5åˆ†é’Ÿï¼‰
        self.cache.insert(
            api_key.to_string(),
            api_key_record.workspace_id.clone(),
        );
        
        Ok(api_key_record.workspace_id)
    }
    
    fn hash_api_key(&self, api_key: &str) -> String {
        let mut hasher = Sha256::new();
        hasher.update(api_key.as_bytes());
        format!("{:x}", hasher.finalize())
    }
}

/// Axum ä¸­é—´ä»¶
pub async fn auth_middleware(
    State(auth): State<Arc<ApiKeyAuth>>,
    headers: HeaderMap,
    request: Request<Body>,
    next: Next,
) -> Result<Response, StatusCode> {
    match auth.verify(&headers).await {
        Ok(workspace_id) => {
            // å°† workspace_id æ³¨å…¥åˆ°è¯·æ±‚æ‰©å±•ä¸­
            let mut request = request;
            request.extensions_mut().insert(workspace_id);
            Ok(next.run(request).await)
        }
        Err(e) => {
            error!("API key verification failed: {:?}", e);
            Err(StatusCode::UNAUTHORIZED)
        }
    }
}
```

#### ä½¿ç”¨ç¤ºä¾‹

```rust
// åº”ç”¨ API Key è®¤è¯ä¸­é—´ä»¶
let app = Router::new()
    .route("/api/v1/generate", post(generate_handler))
    .layer(middleware::from_fn_with_state(
        auth.clone(),
        auth_middleware,
    ));
```

#### API Key ç®¡ç†æ¥å£

```rust
// åˆ›å»º API Key
POST /api/v1/admin/api-keys
{
  "workspace_id": "company-a",
  "description": "Production API Key",
  "expires_at": "2026-12-31T23:59:59Z"
}

// å“åº”
{
  "api_key": "idgen_company-a_a1b2c3d4e5f6g7h8i9j0k1l2m3n4o5p6",
  "expires_at": "2026-12-31T23:59:59Z"
}

// åˆ—å‡º API Keys
GET /api/v1/admin/api-keys?workspace_id=company-a

// åŠé”€ API Key
DELETE /api/v1/admin/api-keys/{key_id}
```
```

#### 9.1.2 PRD ä¿®æ­£

```markdown
### 3.4 å®‰å…¨æ€§éœ€æ±‚ï¼ˆä¿®æ­£ç‰ˆï¼‰

| éœ€æ±‚ | æè¿° | çŠ¶æ€ |
|------|------|------|
| **API è®¤è¯** | åŸºäº workspace çš„ API Key è®¤è¯ | â³ å¾…å®ç° |
| **ä¼ è¾“åŠ å¯†** | æ”¯æŒ TLS 1.3 åŠ å¯† | â³ å¾…å®ç° |
| **è®¿é—®æ§åˆ¶** | API é™æµï¼š1000 QPS/IP | â³ å¾…å®ç° |
| **å¯†é’¥ç®¡ç†** | API Key å®šæœŸè½®è½¬ï¼ˆ90å¤©ï¼‰ | â³ å¾…å®ç° |
| **å®¡è®¡æ—¥å¿—** | è®°å½•æ‰€æœ‰ API è°ƒç”¨å’Œé…ç½®å˜æ›´ | â³ å¾…å®ç° |
| **æ•°æ®åº“å®‰å…¨** | PostgreSQL è¿æ¥åŠ å¯†ï¼Œå¯†ç è½®è½¬ | â³ å¾…å®ç° |
```

#### 9.1.3 Task.md è¡¥å……

```markdown
#### Task 4.2.4: API Key è®¤è¯å®ç° ğŸ”´ â³ å¾…å¼€å‘

**æè¿°**: å®ç°åŸºäº workspace çš„ API Key è®¤è¯

**å‰ç½®ä¾èµ–**: Task 1.2.1 (æ•°æ®åº“è®¾è®¡)

**å®æ–½æ­¥éª¤**:
1. åˆ›å»º `api_keys` è¡¨
2. å®ç° `ApiKeyAuth` ç»“æ„ä½“
3. å®ç° API Key ç”Ÿæˆé€»è¾‘
4. å®ç° API Key éªŒè¯ä¸­é—´ä»¶
5. å®ç° API Key ç®¡ç†æ¥å£ï¼ˆåˆ›å»º/åˆ—å‡º/åŠé”€ï¼‰
6. å®ç°æœ¬åœ°ç¼“å­˜ï¼ˆå‡å°‘æ•°æ®åº“æŸ¥è¯¢ï¼‰

**é¢„ä¼°å·¥æ—¶**: 3 å¤©

**éªŒæ”¶æ ‡å‡†**:
- [ ] API Key æ ¼å¼æ­£ç¡®
- [ ] è®¤è¯ä¸­é—´ä»¶æ­£å¸¸å·¥ä½œ
- [ ] æ— æ•ˆ API Key è¿”å› 401
- [ ] ç®¡ç†æ¥å£å¯ç”¨
- [ ] å®¡è®¡æ—¥å¿—è®°å½•æ‰€æœ‰éªŒè¯
- [ ] å•å…ƒæµ‹è¯•è¦†ç›–ç‡ > 85%
```

---

## åã€ä¿®æ­£æ‰§è¡Œè®¡åˆ’

### 10.1 ä¿®æ­£ä¼˜å…ˆçº§

| ä¼˜å…ˆçº§ | ä¿®æ­£é¡¹ | å½±å“èŒƒå›´ | é¢„ä¼°å·¥æ—¶ |
|-------|-------|---------|---------|
| ğŸ”´ **P0** | æ€§èƒ½ç›®æ ‡ä¿®æ­£ | PRD, TDD, Test, Task | 2 å¤© |
| ğŸ”´ **P0** | ç¼“å­˜æ¶æ„é‡æ„ | TDD, Task | 3 å¤© |
| ğŸ”´ **P0** | DC å·æ®µåˆå§‹åŒ– | TDD, Task | 2 å¤© |
| ğŸ”´ **P0** | RingBuffer ç±»å‹ä¿®æ­£ | TDD, Task | 2 å¤© |
| ğŸ”´ **P0** | API è®¤è¯å®ç° | PRD, TDD, Task | 3 å¤© |
| ğŸŸ  **P1** | æ—¶é’Ÿå›æ‹¨ä¼˜åŒ– | TDD, Test, Task | 2 å¤© |
| ğŸŸ  **P1** | é™çº§æµ‹è¯•è¡¥å…… | Test, UAT | 1 å¤© |
| ğŸŸ  **P1** | Worker ID åˆ†é… | TDD, Task | 2 å¤© |
| ğŸŸ  **P1** | ç¯å¢ƒåˆå§‹åŒ– | Task | 1 å¤© |
| ğŸŸ¡ **P2** | æœ¯è¯­ç»Ÿä¸€ | æ‰€æœ‰æ–‡æ¡£ | 1 å¤© |
| ğŸŸ¡ **P2** | é”™è¯¯ç å®šä¹‰ | TDD | 0.5 å¤© |

**æ€»è®¡**: 19.5 å·¥ä½œæ—¥

### 10.2 ä¿®æ­£é‡Œç¨‹ç¢‘

| é˜¶æ®µ | æ—¶é—´ | äº¤ä»˜ç‰© | çŠ¶æ€ |
|------|------|--------|------|
| **Stage 1** | Day 1-7 | P0 ä¼˜å…ˆçº§ä¿®æ­£å®Œæˆ | â³ å¾…å¼€å§‹ |
| **Stage 2** | Day 8-12 | P1 ä¼˜å…ˆçº§ä¿®æ­£å®Œæˆ | â³ å¾…å¼€å§‹ |
| **Stage 3** | Day 13-15 | P2 ä¼˜å…ˆçº§ä¿®æ­£å®Œæˆ | â³ å¾…å¼€å§‹ |
| **Stage 4** | Day 16-20 | æ–‡æ¡£æ›´æ–°å’Œè¯„å®¡ | â³ å¾…å¼€å§‹ |

---

## åä¸€ã€ä¿®æ­£éªŒæ”¶æ ‡å‡†

### 11.1 æŠ€æœ¯å‡†ç¡®æ€§éªŒæ”¶

- [ ] æ€§èƒ½ç›®æ ‡ç»Ÿä¸€ä¸ºç™¾ä¸‡çº§ QPS
- [ ] RingBuffer æ”¯æŒé€šç”¨ `Id` ç±»å‹
- [ ] æ—¶é’Ÿå›æ‹¨å¤„ç†éé˜»å¡
- [ ] æ‰€æœ‰ä»£ç ç¤ºä¾‹å¯ç¼–è¯‘è¿è¡Œ

### 11.2 ä¸€è‡´æ€§éªŒæ”¶

- [ ] æ‰€æœ‰æ–‡æ¡£æœ¯è¯­ç»Ÿä¸€ï¼ˆbiz_tag, workspace, groupï¼‰
- [ ] ç¼“å­˜æ¶æ„æè¿°ä¸€è‡´ï¼ˆä¸‰çº§ç¼“å­˜ï¼‰
- [ ] é™çº§ç­–ç•¥æµ‹è¯•å®Œæ•´

### 11.3 å®Œæ•´æ€§éªŒæ”¶

- [ ] DC å·æ®µåˆå§‹åŒ– SQL å®Œæ•´
- [ ] Worker ID è‡ªåŠ¨åˆ†é…æ–¹æ¡ˆå®Œæ•´
- [ ] é”™è¯¯ç è¡¨å®šä¹‰å®Œæ•´
- [ ] å¼€å‘ç¯å¢ƒæ­å»ºè„šæœ¬å®Œæ•´

### 11.4 å®‰å…¨æ€§éªŒæ”¶

- [ ] API Key è®¤è¯è®¾è®¡å®Œæ•´
- [ ] å®¡è®¡æ—¥å¿—è®°å½•å®Œæ•´
- [ ] æ•æ„Ÿæ•°æ®åŠ å¯†æ–¹æ¡ˆå®Œæ•´

---

## é™„å½•ï¼šå¿«é€Ÿä¿®æ­£æ¸…å•

### å¿…é¡»ç«‹å³ä¿®æ­£ï¼ˆé˜»å¡å¼€å‘ï¼‰

```
âœ… P0-1: æ€§èƒ½ç›®æ ‡ 100K â†’ 1M QPS
âœ… P0-2: RingBuffer æ”¹ç”¨ crossbeam::ArrayQueue
âœ… P0-3: ç§»é™¤ L2 DashMapï¼Œä½¿ç”¨ DoubleBuffer
âœ… P0-4: è¡¥å…… DC å·æ®µåˆå§‹åŒ– SQL
âœ… P0-5: æ·»åŠ  API Key è®¤è¯æœºåˆ¶
```

### åº”å½“ä¼˜å…ˆä¿®æ­£ï¼ˆå½±å“è´¨é‡ï¼‰

```
âœ… P1-1: æ—¶é’Ÿå›æ‹¨æ”¹ä¸ºéé˜»å¡å¤„ç†
âœ… P1-2: è¡¥å……é™çº§é“¾é›†æˆæµ‹è¯•
âœ… P1-3: å®ç° Worker ID è‡ªåŠ¨åˆ†é…
âœ… P1-4: æ·»åŠ å¼€å‘ç¯å¢ƒ docker-compose
```

### å¯ä»¥åç»­ä¿®æ­£ï¼ˆä¼˜åŒ–ä½“éªŒï¼‰

```
âœ… P2-1: ç»Ÿä¸€æœ¯è¯­ä¸º biz_tag
âœ… P2-2: å®Œå–„é”™è¯¯ç è¡¨
```

---

**æ–‡æ¡£çŠ¶æ€**: ğŸ”´ å¾…æ‰§è¡Œä¿®æ­£  
**é¢„è®¡å®Œæˆæ—¥æœŸ**: 2026-01-15  
**ä¿®æ­£è´Ÿè´£äºº**: æŠ€æœ¯è´Ÿè´£äºº + æ¶æ„å¸ˆ  
**ä¸‹æ¬¡è¯„å®¡æ—¥æœŸ**: 2026-01-20